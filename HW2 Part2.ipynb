{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c8e572-9ceb-4153-8695-f67a9938ecc6",
   "metadata": {},
   "source": [
    "# HW 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46530f-25fa-4e6f-8796-0c6c852ee674",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a79511-28e9-4419-8061-5da719c99833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,QuantileTransformer\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c812e073-88f9-4b26-84b8-fe7908f6e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Lowess as Lowess\n",
    "import Logistic as LowessLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee159c-ac59-4f8c-81f1-c0824671c63f",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "Implement your own version of Locally Weighted Logistic Regression and compare its performance on the Iris data set with the version presented in this article: https://calvintchi.github.io/classical_machine_learning/2020/08/16/lwlr.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da631247-68aa-43c2-b118-6b36c17f0c8d",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8bf85f-6e9c-4163-80a8-f0e096f20bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Kernels\n",
    "\n",
    "# Gaussian Kernel\n",
    "def Gaussian(x):\n",
    "  return np.where(np.abs(x)>4,0,1/(np.sqrt(2*np.pi))*np.exp(-1/2*x**2))\n",
    "    \n",
    "# Tricubic Kernel\n",
    "def Tricubic(x):\n",
    "  return np.where(np.abs(x)>1,0,(1-np.abs(x)**3)**3)\n",
    "    \n",
    "# Epanechnikov Kernel\n",
    "def Epanechnikov(x):\n",
    "  return np.where(np.abs(x)>1,0,3/4*(1-np.abs(x)**2))\n",
    "    \n",
    "# Quartic Kernel\n",
    "def Quartic(x):\n",
    "  return np.where(np.abs(x)>1,0,15/16*(1-np.abs(x)**2)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff729899-afc7-4b6a-9864-4714a6a08219",
   "metadata": {},
   "source": [
    "### Importing iris data, TTS, and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5694c12-d799-43b6-bfff-b836287c3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data from sklearn\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead589ab-1c65-47fc-9e69-20de8388495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining x and y variables\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf44e5d-b132-4103-9603-1a9f9c3f784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2699fcfe-c6ef-4760-9812-b28537369e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data using MinMax Scaler, can also use other scalers which are currently commented out\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "#scaler = QuantileTransformer()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec234f1-a491-49d2-91df-7b3dd6d03ce3",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a48034-4153-494e-ac61-f6e732b93bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a LocallyWeightedLogisticRegression model with Gaussian kernel, learing rate of  0.01, and tau=0.05\n",
    "model = LowessLR.LocallyWeightedLogisticRegression(kernel=Gaussian, lr=0.01, tau=0.05) # accuracy of .97\n",
    "\n",
    "#model = LowessLR.LocallyWeightedLogisticRegression(kernel=Tricubic, lr=0.01, tau=0.05) # accuracy of .97\n",
    "#model = LowessLR.LocallyWeightedLogisticRegression(kernel=Epanechnikov, lr=0.01, tau=0.05) # accuracy of .97\n",
    "#model = LowessLR.LocallyWeightedLogisticRegression(kernel=Quartic, lr=0.01, tau=0.05) # accuracy of .97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495ff138-bcde-4d06-8c57-95e622fb0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting model to training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e5f329-e880-48b2-9b25-8c1b76fed6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using trained model to make predictions on test data\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b056ed66-0e37-485b-81fe-574912b36411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy of predictions compared to the true labels (y_test) and printing results\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526294cf-335d-4df3-a0f1-328896ed9f50",
   "metadata": {},
   "source": [
    "## Comparing results to Calvin Chi Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0453540-6523-4085-9f50-85f3c81a31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version presented in Calvin Chi article\n",
    "\n",
    "class locally_weighted_logistic_regression(object):\n",
    "    \n",
    "    def __init__(self, tau, reg = 0.0001, threshold = 1e-6):\n",
    "        self.reg = reg\n",
    "        self.threshold = threshold\n",
    "        self.tau = tau\n",
    "        self.w = None\n",
    "        self.theta = None\n",
    "        self.x = None\n",
    "\n",
    "    def weights(self, x_train, x):\n",
    "        sq_diff = (x_train - x)**2\n",
    "        norm_sq = sq_diff.sum(axis = 1)\n",
    "        return np.ravel(np.exp(- norm_sq / (2 * self.tau**2)))\n",
    "\n",
    "    def logistic(self, x_train):\n",
    "        return np.ravel(1 / (1 + np.exp(-x_train.dot(self.theta))))\n",
    "\n",
    "    def train(self, x_train, y_train, x):\n",
    "        self.w = self.weights(x_train, x)\n",
    "        self.theta = np.zeros(x_train.shape[1])\n",
    "        self.x = x\n",
    "        gradient = np.ones(x_train.shape[1]) * np.inf\n",
    "        while np.linalg.norm(gradient) > self.threshold:\n",
    "            # compute gradient\n",
    "            h = self.logistic(x_train)\n",
    "            gradient = x_train.T.dot(self.w * (np.ravel(y_train) - h)) - self.reg * self.theta\n",
    "            # Compute Hessian\n",
    "            D = np.diag(-(self.w * h * (1 - h)))\n",
    "            H = x_train.T.dot(D).dot(x_train) - self.reg * np.identity(x_train.shape[1])\n",
    "            # weight update\n",
    "            self.theta = self.theta - np.linalg.inv(H).dot(gradient)\n",
    "    \n",
    "    def predict(self,x):  # adjusted slightly to allow for input feature\n",
    "        return np.array(self.logistic(x) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7e37f37-b523-4b57-8945-90f48807ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training one v rest models\n",
    "model_dict = {}  # initialize dictionary to store models\n",
    "\n",
    "# training a model for each class\n",
    "for cls in np.unique(y_train):  # iterating over each unique class label in the training data\n",
    "    binary_y_train = (y_train == cls).astype(int)  # creating binary target variable for current class\n",
    "    model = locally_weighted_logistic_regression(tau=.05)  # initializing model\n",
    "    model.train(X_train, binary_y_train, X_train)  # training  model\n",
    "    model_dict[cls] = model  # storing model for given class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e053713f-6db9-4fb9-94ab-854a665f8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "predictions = []  # initializing list to store predictions\n",
    "\n",
    "for x_test in X_test: # iterating over each test sample\n",
    "    class_probs = [] # initializing list to store probabilities for each class\n",
    "    \n",
    "    for cls, model in model_dict.items():  # iterating over the items in model_dict\n",
    "        prob = model.predict(x_test.reshape(1, -1))  # calling predict method of current model to get prediction\n",
    "        class_probs.append(prob[0])  # appends predicted probability for current class to class_probs list\n",
    "    \n",
    "    # after evaluating all classes for current test sample, determine class with highest probability\n",
    "    predictions.append(np.argmax(class_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3bd021-1249-434a-9371-4731724e0e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy of predictions compared to the true labels (y_test) and printing results\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5837626a-155d-43b8-9f25-5a07b737d658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c621fb-b4d0-4ab0-b99e-7ea737a94caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
